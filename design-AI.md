# Designing your Complex Info Processing System (_AI_)
# By Laurence Keck
<br /><br />

# 1. Name a real-world example of an existing AI system that is problematic in that it actually enacts existing problematic social systems/practices
+ A real world example of an artificial intelligence that might be problematic in society is AI that generates Deep Fakes and Fake News for social media. This actually worsens the societal problem of false information and misinformation on the internet. The artificial intelligence that exists can mass produce this misinformation in seconds on any topic. The deep fakes over the years has gotten really problematic as they have gotten more and more realistic. The AI can mimic faces, voices, and even text messages.

<br /><br />

# 2. Describe this system in terms of (your perceived high-level) **goals**, **environment**, and **adaptations** of the system.

<br /><br />

### Goals

+ Generate text, images, audio, or video content automatically.
+ To mimic person-generated media (voice, video, and text) to convince people it is real.
+ To Spread false information, propaganda, or misinformation for various purposes, including political manipulation and disinformation campaigns.

These goals are problematic to society and can hurt the public.

<div style="margin-bottom: 265px;">&nbsp;</div>

### Environment

+ Operates on the internet across various platforms, including social media, websites, and messaging apps.
+ Utilizes machine learning models to create realistic-looking and sounding content.
+ Can reach a global audience, impacting public perception and trust in the media.

<div style="margin-bottom: 265px;">&nbsp;</div>

### Adaptation

+ Adapts by continuously improving the quality of generated content through machine learning.
+ Evolves to bypass detection methods used by most media outlets such as instagram, twitter, or youtube by constantly changing generation techniques.
+ Adapt to current events, trending topics, or popular people to maximize disinformation.
+ Frequently updates and refines algorithms to get better at imitating human speech, and behavior.

<br /><br />

# 3. Describe a potential reimagined system in terms of **goals**, **environment**, and **adaptations**. How does it improve upon the system described in 2?

<br /><br />

### Goals

+ Shift the primary goal from spreading misinformation to generating ethical content.
+ TO be more ethical in the genration of the content for media outlets.
+ Enhance content quality and utility for legitimate purposes, such as education, true information, and even comedic purposes.

<div style="margin-bottom: 265px;">&nbsp;</div>

### Environment

+ The environment would be the same as the old AI system mainly.
+ It would emphasize ethical and responsible use of the AI.

<div style="margin-bottom: 265px;">&nbsp;</div>

### Adaptation

+ Adapts by refining itself to stay up to date with ethical guidelines and content standards.
+ Collaborates with platforms to implement stricter content policies and provide ethical content creation tools.
+ Encourages content creators to follow responsible AI use, including avoiding harmful and deceptive content and misinformation that would cause distrust in the media.
+ Offers feedback to creators on improving their content's ethics.

This reimagined system would not only rid of the harmful misinformation, deep fakes, and fake news, but it could actually help society solve the problem of mistrust in the media. A better AI system that detects fake news would also be helpful, but actually reimagining the current AI system to detect itself generating fake news, and being able to stop it at the source would likely be most useful. 